---
title: "PSY 503: Foundations of Statistical Methods in Psychological Science"
subtitle: "More LM: Moderation/Interactions"
institute: "Princeton University"
author: "Jason Geller, Ph.D. (he/him/his)"
date:  'Updated:`r Sys.Date()`'
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    nature:
      slideNumberFormat: "%current%"
      highlightStyle: github
      highlightLines: true
      ratio: 16:9
      countIncrementalSlides: true
      background-image: url("lover.png")
      background-size: cover
      
---
```{r xaringan-extra-styles, echo=FALSE}
library(xaringanExtra)
xaringanExtra::use_extra_styles(
  hover_code_line = TRUE,         #<<
  mute_unhighlighted_code = TRUE  #<<
)
```

```{html, echo=FALSE}
<div style = "position:fixed; visibility: hidden">
$$\require{color}\definecolor{yellow}{rgb}{1, 0.8, 0.16078431372549}$$
$$\require{color}\definecolor{orange}{rgb}{0.96078431372549, 0.525490196078431, 0.203921568627451}$$
$$\require{color}\definecolor{green}{rgb}{0, 0.474509803921569, 0.396078431372549}$$
</div>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
    Macros: {
      yellow: ["{\\color{yellow}{#1}}", 1],
      orange: ["{\\color{orange}{#1}}", 1],
      green: ["{\\color{green}{#1}}", 1]
    },
    loader: {load: ['[tex]/color']},
    tex: {packages: {'[+]': ['color']}}
  }
});
</script>
<style>
.yellow {color: #FFCC29;}
.orange {color: #F58634;}
.green {color: #007965;}
</style>
```{r, echo=FALSE}
library(flair)
yellow <- "#FFCC29"
orange <- "#F58634"
green <- "#007965"
```


```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  fig.width=9, fig.height=3.5, fig.retina=3,
  out.width = "50%",
  tidy.opts=list(width.cutoff=60),tidy=TRUE, 
  cache = FALSE,
  echo = TRUE,
  message = FALSE, 
  warning = FALSE,
  fig.show = TRUE,
  hiline = TRUE
)
hook_source <- knitr::knit_hooks$get('source')
knitr::knit_hooks$set(source = function(x, options) {
  x <- stringr::str_replace(x, "^[[:blank:]]?([^*].+?)[[:blank:]]*#<<[[:blank:]]*$", "*\\1")
  hook_source(x, options)
})
```

<div style = "position:fixed; visibility: hidden">
$$\require{color}\definecolor{red}{rgb}{1, 0, 0}$$
$$\require{color}\definecolor{green}{rgb}{0, 1, 0}$$
$$\require{color}\definecolor{blue}{rgb}{0, 0, 1}$$
</div>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
    Macros: {
      red: ["{\\color{red}{#1}}", 1],
      green: ["{\\color{green}{#1}}", 1],
      blue: ["{\\color{blue}{#1}}", 1]
    },
    loader: {load: ['[tex]/color']},
    tex: {packages: {'[+]': ['color']}}
  }
});
</script>

<style>
.red {color: #FF0000;}
.green {color: #00FF00;}
.blue {color: #0000FF;}
</style>


```{r flair_color, echo=FALSE}
library(flair)
red <- "#FF0000"
green <- "#00FF00"
blue <- "#0000FF"
```


```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_solarized_dark(
  header_font_google = google_font("Work Sans"),
  header_h1_font_size = "36px",
  header_color = "black",
  text_font_google = google_font("Work Sans"),
  text_font_size = "30px",
  text_color = "black", 
  background_color = "white", 
  code_font_google = google_font("Share Tech Mono"),
  extra_css = list(
    ".remark-slide-content h2" = list(
      "margin-top" = "2em",
      "margin-bottom" = "2em"
    ),
    .big = list("font-size" = "150%"),
    .small = list("font-size" = "75%"),
    .subtle = list(opacity = "0.6"),
    ".countdown-has-style h3, .countdown-has-style h3 ~ p, .countdown-has-style h3 ~ ul" = list(
      "margin" = "0"
    ),
    ".countdown-has-style pre" = list(
      "margin-top" = "-10px"
    ),
    "p .remark-inline-code" = list(
      "background-color" = "white",
      "padding" = "2px 2px",
      "margin" = "0 -2px"
    ),
    blockquote = list("margin-left" = 0),
    "em" = list(color = "#2aa198")
  ),
)
```

```{r, echo=FALSE}
library(parameters)
library(effectsize) 
library(papaja)
library(tidyverse)
library(performance)
library(see)
library(equatiomatic)
library(kableExtra)
library(stargazer)
library(broom)
library(easystats)
library(interactions)
library(report)
library(emmeans)
library(flextable)
library(huxtable)
library(skimr)
library(papaja)
library(moderndive)
```
# Outline

- Testing interactions/moderation analysis

  - Categorical by Continuous
  - Continuous by Continuous
  - Categorical by Categorical (Monday)
    
---
# Interactions

```{r, eval=FALSE}

lm(plant_growth ~ sun_exposure + water)

```

---
# Interactions

```{r, eval=FALSE}

lm(plant_growth ~ sun_exposure +  water)

```

```{r, echo=FALSE, fig.align='center', out.width="100%"}

knitr::include_graphics("sun-water.bmp")
```
---
# Interactions
```{r, eval=FALSE}

lm(plant_growth ~ sun_exposure * water)

```

```{r, echo=FALSE, fig.align='center', out.width="100%"}

knitr::include_graphics("plant-sun.png")
```
---
# Interactions

```{r, eval=FALSE}

lm(plant_growth ~ sun_exposure * water)

```

```{r, echo=FALSE, fig.align='center', out.width="100%"}

knitr::include_graphics("sun-inter.png")
```
---
# What is a moderator?

```{r, echo=FALSE, fig.align='center', out.width="100%"}

knitr::include_graphics("moderation1.png")
```
$$Y=\beta_{0}+\beta_{1}*X+\epsilon$$
---
# What is a moderator?

- A moderator variable Z is a variable that alters the strength of the relationship between X and Y

```{r, echo=FALSE, fig.align='center', out.width="90%"}

knitr::include_graphics("moderation2.png")
```

---
# What Do Interactions Look Like?

```{r, echo=FALSE, fig.align='center', out.width="90%"}

knitr::include_graphics("types-of-interaction-flat.png")
```
---
class: middle

# Categorical x Continuous Interactions

---
# Today's Dataset

- Student evaluations for a sample of 463 courses taught by 94 professors from the University of Texas at Austin

- Six students rated the professors' physical appearance 

```{r}
evals_agegend=read_csv("https://raw.githubusercontent.com/jgeller112/psy503-psych_stats/master/evals.csv")
evals1= evals_agegend %>%
dplyr::select(ID, score, age, gender)
```

```{r, echo=FALSE}
summary(evals)
```
---
# Research Question

- Does Age and Sex (Males, Females) of the instructor influence instructor ratings?

    - DV: Evals
    - IV:
        - Age 
        - Gender
        - Age*Gender Interaction
---
# Scatterplot

```{r, fig.align='center', out.width="100%"}
ggplot(evals1, aes(x = age, y = score, color = gender)) +
  geom_point() +
  labs(x = "Age", y = "Teaching Score", color = "Gender") +
  geom_smooth(method = "lm", se = FALSE)
```

---
# How to Conduct Moderation Analysis?

- Moderation analysis can be conducted by adding one or multiple interaction terms in a regression analysis

Z is a moderator for the relation between  X and  Y, we can fit a regression model

$$\begin{eqnarray*} 
Y & = & \beta_{0}+\beta_{1}*X+\beta_{2}*Z+\beta_{3}*X*Z+\epsilon\\ & = & \begin{cases} \beta_{0}+\beta_{1}*X+\epsilon & \mbox{For females}(Z=0)\\ \beta_{0}+\beta_{2}+(\beta_{1}+\beta_{3})*X+\epsilon & \mbox{For males}(Z=1) \end{cases} \end{eqnarray*}$$

- When Z=0 (females),the effect of X on Y is β1+β3∗0=β1

- When Z=1 (males), the effect of X on Y is β1+β3∗1 

---
# Steps for Moderation Analysis

A moderation analysis typically consists of the following steps:

1. Compute the interaction term XZ=X*Z 

2.  Fit a multiple regression model with X, Z, and XZ as predictors

3.  Test whether the regression coefficient for XZ (interaction) is significant

4.  If so, interpret the moderation effect (ignore main effects)

5.  Display the moderation effect graphically
---
# Steps for moderation analysis

-  Compute the interaction term XZ=X*Z

  - Center continuous variables

    - Centering solves two problems: 
    
      - Interpretation
      
      - Multicollinearity

```{r}
evals_interact <- evals1 %>%
  mutate(age_c=datawizard::center(age),gender_trt=ifelse(gender=="female", 0, 1), inter=age_c*gender_trt)
```
---
# Steps for moderation analysis

-  Fit a multiple regression model with X, Z, and XZ as predictors

```{r}
lm(evals_interact$score~age_c*gender_trt, data=evals_interact) %>%
  tidy()
```
---
# Steps for moderation analysis

- Test whether the regression coefficient for XZ is significant

```{r}
lm(score~age_c*gender_trt, data=evals_interact) %>%
  tidy()
```
---
# Interpretation

$$\hat{Y}= b_0 + b_1 X + b_2 Z + b_3 X*Z$$

- $b_0$: the intercept, or the predicted outcome when  X = 0 and Z=0
- $b_1$: the simple effect or slope of $X$, for a one unit change in $X$ the predicted change in $Y$  at  $Z = 0$
- $b_2$: The offset/difference in the intercept for a one unit change in $Z$ the predicted change in Y  at X  = 0 
- $b_3$: The interaction of $X$ and $Z$, the offset in slope for $Z$ for a one-unit increase in $X$ (or vice versa)
---
# Interpretation

```{r}
lm(score~age_c*gender_trt, data=evals_interact) %>%
 tidy()
```
$b_0$ = 
$b_{age}$ = 
$b_{gender}$ = 
$b_{age}*{male}$ = 

???

Average Score for females is at average age 

age_c: slope of age for z = 0 (females) b0 + b1 + b2(0) + b3 (0)

gender M: slope offset for difference between males and females at average age

age_c*gender: the offset slope males

---
# Moderation: Simple Slopes

- If the interaction is significant, then you usually ignore the other individual effects (age and gender)

- So what do I do if my interaction is significant? **A simple slope analysis**

---
# Main vs. Simple Effects (slopes)

- Main Effects

  - Coefficients that do no involve interaction terms
  
  - Comparison of marginal means

.pull-left[

```{r, echo=FALSE, fig.align='center', out.width="100%"}

knitr::include_graphics("marginalMean9.png")

```
]

.pull-right[
$$\hat{Y}= b_0 + b_1 X + b_2 Z$$

-$b_0$: The intercept, or the predicted outcome when  X and Z are 0
-$b_1$: The slope (or main effect) of X ; for a one unit change in  the predicted change in Y
-$b_2$: The slope (or main effect) of Y ; for a one unit change in  the predicted change in Y
]
---
# Main vs. Simple effects (slopes)

- Simple Effects

  - Comparison of cell means

$$\hat{Y}= b_0 + b_1 X + b_2 Z + b_3 X*Z$$
- $b_0$: the intercept, or the predicted outcome when  X = 0 and Z=0
- $b_1$: the simple effect or slope of $X$, for a one unit change in $X$ the predicted change in $Y$  at  $Z = 0$
- $b_2$:The simple effect or slope of $Z$, for a one unit change in $Z$ the predicted change in Y  at X  = 0 
- $b_3$:The interaction of $X$ and $Z$, the change in the slope of $X$ for a one-unit increase in $Z$ (or vice versa)

---
# Steps for Moderation Analysis

- Obtain simple slopes

  - When a continuous independent variable interact with a moderating variable, its slope at a particular level of the moderating variable

  - Test if slope $\neq$ 0 

```{r}
#hello to our friend emmeans 
#library(emmeans)
d=lm(score~age_c*gender_trt, data=evals_interact)

emtrends(d, ~ gender_trt, var="age_c") #simple slopes
```
---
# Simple Slopes

```{r}

sim_slopes(d, pred=age_c, modx=gender_trt)

```
---
# Steps for Moderation Analysis

- Difference in slopes

  - *Testing simple slopes is not the same thing as testing their difference*

```{r}
d=lm(score~age_c*gender_trt, data=evals_interact)

emtrends(d, pairwise ~ gender_trt, var="age_c")
```
---
# Interactions 

- You should only be following up interactions if significant! 

```{r, echo=FALSE, fig.align='center', out.width="80%"}

knitr::include_graphics("gelman.png")

```

---
# Visualize 

```{r, fig.align='center', out.width="90%"}
ggplot(evals1, aes(x = age, y = score, color = gender)) +
  geom_point() +
  labs(x = "Age", y = "Teaching Score", color = "Gender") +
  geom_smooth(method = "lm", se = FALSE)

```

---
# Parallel Slopes

- Parallel slopes models still allow for different intercepts but force all lines to have the same slope.

```{r, fig.align='center', out.width="80%"}
ggplot(evals1, aes(x = age, y = score, color = gender)) +
  geom_point() +
  labs(x = "Age", y = "Teaching Score", color = "Gender") +
  geom_parallel_slopes(se = FALSE)
```
---
# Parallel Slopes

```{r}
main<-lm(score~age_c + gender_trt, data=evals_interact) 
inter<- lm(score~age_c*gender_trt, data=evals_interact)

anova(main, inter)
```
---
# Parallel Slopes

<br>
<br>

.pull-left[

```{r, echo=FALSE, fig.align='center', out.width="100%"}
ggplot(evals_interact, aes(x = age, y = score, color = gender)) +
  geom_point() +
  labs(x = "Age", y = "Teaching Score", color = "Gender") +
  geom_smooth(method = "lm", se = FALSE)
```

]
.pull-right[

```{r, echo=FALSE, fig.align='center', out.width="100%"}
ggplot(evals_interact, aes(x = age, y = score, color = gender)) +
  geom_point() +
  labs(x = "Age", y = "Teaching Score", color = "Gender") +
  geom_parallel_slopes(se = FALSE)
```
]
---
# Practice In-Class Activity

- Pick a new categorical and continuous variable to examine if they interact with teaching evals

- Go through the steps outlined in the lecture

- Be ready to talk as a group about what you ran and found

```{r}

evals_agegend=read_csv("https://raw.githubusercontent.com/jgeller112/psy503-psych_stats/master/evals.csv")

```
---
# Today


- Weekly Q & A

- More interactions! 

---
# Last Class

- Test of one simple slope for one group can be extracted from the summary output (age_c:women slope)

- Sum coded categorical variable 
---
# Effect Sizes

- Effect size for moderation

  - *d* for the difference (t-test)

  - For specific effects $\eta_p^2$ 

```{r}
library(effectsize)
inter<- lm(score~age_c*gender_trt, data=evals_interact)
effectsize::eta_squared(inter) # partial eta squared
```
---
# Multicollinearity

```{r, echo=FALSE}
data(state)

data=as.data.frame(state.x77)

data_c <- data  %>%
  mutate(murder_c=datawizard::center(Murder), income_c=datawizard::center(Income), murder_z=scale(murder_c), income_z=scale(income_c), life=scale(`Life Exp`))
```

```{r}

not_c<- lm(`Life Exp`~Murder*Income, data=data_c ) %>% 
  tidy() %>%
  mutate_if(is.numeric, round, 3)

c<- lm(`Life Exp`~murder_c*income_c, data=data_c ) %>%
  tidy() %>% 
  mutate_if(is.numeric, round, 3)

```
---
# Standardizing Data vs. Coef

- Same thing

.pull-left[
```{r}

z <- lm(`Life Exp`~scale(Murder)*scale(Income), data=data_c) %>%
 model_parameters()

z

z_coef<-lm(`Life Exp`~murder_c*income_c, data=data_c) %>%
 standardize_parameters(
include_response=FALSE) # by default standardizes response/outcome

z_coef
```

---
# Parallel Slopes

- In practice, you will probably always care about interactions, However...

```{r}
main<-lm(score~age_c + gender_trt, data=evals_interact) 

inter<- lm(score~age_c*gender_trt, data=evals_interact)

anova(main, inter)
```

---
class: middle 
# Continuous x Continuous Interactions
---
# Continuous x Continuous Interactions

- Do violent video games make people aggressive? 

    - DV: Aggression
    - IV:
    
        - Callous unemotional traits 
        - Number of hours spent playing video games per week
        - Callous unemotional traits*Number of hours spent playing video games per week

```{r}
# download dataset
moderation_vio=read_csv("https://raw.githubusercontent.com/jgeller112/psy503-psych_stats/master/moderation.csv")
```

---
# Continuous x Continuous Interactions

- The center of each IV represents the mean of that IV

- Thus when you interact them $X*Z$, that means $0*0 = 0$

- Also, this can reduce multicollinearity issues

  - This is because if $X*Z$ creates a line, it means you have added a new predictor (XZ) that strongly correlates with X and Z

```{r}
library(datawizard)
moderation_vio <- moderation_vio %>%
  mutate(vid_games_c=center(Vid_Games), caunts_c=center(CaUnTs))

```
---
# How does this look?

```{r, echo=FALSE}

knitr::include_graphics("interexamp.png")
```
---
# Continuous X Continuous Interactions

- If the Z (moderato variable) was categorical, you are basically checking if the separate groups (levels) have different slopes for the non-categorical variable

- However, we cant do that with continuous x continuous interactions

---
# Continuous X Continuous Regression

```{r}
ds=lm(Aggression~ vid_games_c*caunts_c,  data=moderation_vio) %>%
  tidy()
```


???

(Intercept): the intercept, or the predicted outcome when hours = 0 and traits = 0.
 hours: the simple slope of Hours, for a one unit change in Hours, the predicted change in weight loss at Effort=0. 
triat: the simple slope of trait, for a one unit change in vio the predicted change in trait at Hours=0.
 hours:effort: the interaction of Hours and Effort, the change in the slope of Hours for every one unit increase in Effort (or vice versa).
 
---
# Interpretation Continuous x Continuous Interactions

- $b_0$: the intercept, or the predicted outcome when  X = 0 and Z=0
- $b_1$: the simple effect or slope of $X$, for a one unit change in $X$ the predicted change in $Y$  at  $Z = 0$
- $b_2$: The simple effect or slope of $Z$, for a one unit change in $Z$ the predicted change in Y  at X  = 0 
- $b_3$:The interaction of $X$ and $Z$, the change in the slope of $X$ for a one-unit increase in $Z$ (or vice versa)
---

# Decomposing Continuous X Continuous Interaction: Spotlight Analysis

- For continuous moderator variables, you "create" low, average, and high groups

    - Low groups are people who are one SD below the mean
    - Average groups are people are at the mean
    
    - High groups are people who are one SD above the mean 
---
# Moderation: Simple Slopes

- We are examining the interaction between hours of video games and unemotional traits to predict aggression

- Think about which variable you want to know the differences in (i.e., low, average, high)

- So at different levels of callousness, we want to examine the relationship between hours of video game play and aggression
---
# Probing Interactions: Spotlight Analysis

- Low/below mean created by *SUBTRACTING* 1 SD

- High/above mean created by *ADDING* 1 SD

- The rule is that we have to bring them to the middle because we centered so that zero is the middle

```{r}
#create the low and high z score variables 
a <- mean(moderation_vio$caunts_c) + sd(moderation_vio$caunts_c)

at <- mean(moderation_vio$caunts_c)

b <- mean(moderation_vio$caunts_c) - sd(moderation_vio$caunts_c)

```

---
# Spotlight Analysis

```{r}

# create a list for values at a, b, and mean and round them
mylist <- list(caunts_c=c(round(b, 1), round(at,1), round(a, 1)))

# run lm again
d=lm(Aggression~vid_games_c*caunts_c,data=moderation_vio)

# get simple slopes at each level at b a
emtrends(d,~caunts_c, var="vid_games_c", at=mylist)

```
--

- At high levels of callousness, the strength of hours of video games predicting aggression is the strongest, b = 0.43 ... 

---
# Graphing Continuous x Continuous Interactions

```{r, echo=TRUE}
moderation_vio$caunts_clow <- moderation_vio$caunts_c + sd(moderation_vio$caunts_c) #bring them up
moderation_vio$caunts_chigh <- moderation_vio$caunts_c - sd(moderation_vio$caunts_c) #bring them down
modmodellow <- lm(Aggression ~ vid_games_c*caunts_clow, data = moderation_vio)
modmodelhigh <- lm(Aggression ~ vid_games_c*caunts_chigh, data = moderation_vio)
```

```{r, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center', out.width="100%"}
library(ggplot2)

cleanup <- theme(panel.grid.major = element_blank(), 
                panel.grid.minor = element_blank(), 
                panel.background = element_blank(), 
                axis.line.x = element_line(color = "black"),
                axis.line.y = element_line(color = "black"),
                legend.key = element_rect(fill = "white"),
                text = element_text(size = 15))
modgraph <- ggplot(moderation_vio, aes(vid_games_c, Aggression))
##change Cal to the new moderator label
##change xlab for the new X label
modgraph + 
  xlab("Centered Video Games") + 
  geom_point(color = "gray") +
  geom_abline(aes(intercept = modmodellow$coefficients[1],
                  slope = modmodellow$coefficients[2], 
                  linetype = "-1SD Cal"), size = 1) +
  geom_abline(aes(intercept = d$coefficients[1],
                  slope = d$coefficients[2], 
                  linetype = "Average Cal"), size = 1) +
  geom_abline(aes(intercept = modmodelhigh$coefficients[1],
                  slope = modmodelhigh$coefficients[2], 
                  linetype = "+1SD Cal"), size = 1) +
  scale_linetype_manual(values = c("dotted", "dashed", "solid"),
                        breaks = c("-1SD Cal", "Average Cal", "+1SD Cal"),
                        name = "Simple Slope") +
  cleanup 
```
---
# Graphing Continuous x Continuous Interactions

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', out.width="100%"}
library(ggplot2)

cleanup <- theme(panel.grid.major = element_blank(), 
                panel.grid.minor = element_blank(), 
                panel.background = element_blank(), 
                axis.line.x = element_line(color = "black"),
                axis.line.y = element_line(color = "black"),
                legend.key = element_rect(fill = "white"),
                text = element_text(size = 15))
modgraph <- ggplot(moderation_vio, aes(vid_games_c, Aggression))
##change Cal to the new moderator label
##change xlab for the new X label
modgraph + 
  xlab("Centered Video Games") + 
  geom_point(color = "gray") +
  geom_abline(aes(intercept = modmodellow$coefficients[1],
                  slope = modmodellow$coefficients[2], 
                  linetype = "-1SD Cal"), size = 1) +
  geom_abline(aes(intercept = d$coefficients[1],
                  slope = d$coefficients[2], 
                  linetype = "Average Cal"), size = 1) +
  geom_abline(aes(intercept = modmodelhigh$coefficients[1],
                  slope = modmodelhigh$coefficients[2], 
                  linetype = "+1SD Cal"), size = 1) +
  scale_linetype_manual(values = c("dotted", "dashed", "solid"),
                        breaks = c("-1SD Cal", "Average Cal", "+1SD Cal"),
                        name = "Simple Slope") +
  cleanup 
```
---
# Probing Interactions: Simplier Way

- Use `interact plot` from the `interactions package`

```{r, fig.align='center', out.width="80%"}
library(interactions)

interact_plot(d, pred = vid_games_c, modx = caunts_c, interval = TRUE)

```

---
# Probing Interactions: Johnson-Neyman Plot

.pull-left[

- Is a Floodlight analysis on the whole range of the moderator

- Provides an interval (2 points) where the slope of a predictor is not statistically significant across different values of the mediator

```{r, echo=TRUE, warning=FALSE, message=FALSE, fig.align='center', eval=FALSE}
johnson_neyman(model = d, pred = vid_games_c,
  modx = caunts_c, control.fdr = TRUE) # important bc otherwise does not correct for multiple comparisons
```

]
<br>
<br>
.pull-right[

```{r, echo=FALSE, fig.align='center', out.width="100%", warning=FALSE, message=FALSE, fig.align='center'}

knitr::include_graphics("JNplot.png")
```


]
---
# Moderation: MeMoBootR

- We can use the `MeMoBootR` to complete the entire processing, including data screening for us! 

- You would enter the raw variables, as the centering is completed for you

```{r}
#devtools::install_github("doomlab/MeMoBootR")
library(MeMoBootR)
mod_model <- moderation1(y = "Aggression",
                         x = "Vid_Games",
                         m = "CaUnTs",
                         df = moderation_vio)
```
---
# Moderation: MeMoBootR

```{r}
#data screenin
#mod_model$datascreening$fulldata
#models
#summary(mod_model$model1)
#mod_model$interpretation
#graphs
#mod_model$graphslopes
```
---
# In-Class Activity

- High school and beyond dataset

> A national longitudinal survey of students from public and private high schools in the United States, with information such as students' cognitive and non-cognitive skills, high school experiences, work experiences and future plans collected.

- Pick two continuous variables to model

- Plot their interaction and test for significance using both the spotlight and floodlight analyses

```{r}
library(descriptr)
hsb=descriptr::hsb

summary(hsb)

```
---
class: middle

# Categorical x Categorical Interaction
---
# Categorical x Categorical Interaction

- Factorial design

  - Commonly used to refer to experiments where more than one factor is manipulated

  - 2-way (most common), 3-way factorial designs, 4-way... 

> Brysbaert, M. (2019). How many participants do we have to include in properly powered experiments? A tutorial of power analysis with reference tables. Journal of Cognition, 2(1), 16. DOI: http://doi.org/10.5334/joc.72

---
# Types of Categorical x Categorical Interactions

```{r,echo=FALSE, fig.align='center', out.width="100%"}

knitr::include_graphics("interpinter1.png")
```
---
# Interpretation Interactions
```{r, echo=FALSE, fig.align='center', out.width="100%"}

knitr::include_graphics("interinter3.png")
```
---
# 2 x 2 Between Factorial Dataset

- LaPaglia, Miller, and Protexter (2022)

  - Looked at the impact of instructor fluency and gender on test performance
  
  - *N* = 72 (49 females, 23 males)
  
  - 2 (Fluency: fluent, disfluent) x 2 (Gender: male, female) design

```{r}
gen<- read_csv("https://raw.githubusercontent.com/jgeller112/psy503-psych_stats/master/static/slides/13_Interactions/in_gen_2x2.csv")

gen <- gen %>%
  mutate(Gender=as.factor(Gender), Fluency=as.factor(Fluency)) %>%
  rename("id" = `Subject Number`)
```
---
# 2-way (Factorial) ANOVA

- In the example above we have two factors
Factor A (e.g., Gender) with 2 levels (e.g., male vs. female)
Factor B (e.g., Fluency) with 2 levels (e.g., Disfluency vs. Fluency)

- Fully crossed design
  - Every level of factor A is tested with every level of factor B
  - total # groups (cells) is a x b

- We will see how to formulate in terms of model comparisons:

  - Main effect of A
  - Main effect of B
  - Interaction effect A x B
---
Same approach as before

$$F = \frac{SS_{R}-SS_{F}/{df_{R}-df_{F}} (p-1)}{SS_{F}/df_F(N-p)} = \frac{MS_{model}}{MS_{error}}$$

1. Write the equation for the full and restricted models

2. Derive the equations for model error restricted and full

3. Derive the expressions for degrees of freedom df restricted and df full

4. End up with an equation for the F ratio

---
# Full Model

$$Y_{ijk} = \mu + \alpha_j + \beta_k + (\alpha* \beta)_{ijk}$$

- $Y_{ijk}$: is an individual score in the jth level of factor A and the kth level of factor B (i
indexes subjects within each (j,k) cell)

-  $µ$: is the overall mean of all cells
- $α_j$: is the effect of the jth level of factor A
- $β_k$: is the effect of the kth level of factor B
- $(α · β)_{jk}$: is the interaction effect of level j of A and level k of B
---
# Hypothesis Testing using Modeling Approach

- Two-Factor (A x B) design: 3 null hypotheses to be tested:

  - Main effect of A
  - Main effect of B
  - Interaction effect of A x B
  
- We will formulate a separate restricted model for each hypothesis test

- Each test will involve the same full model we will use the usual F test

$$F = \frac{SS_{R}-SS_{F}/{df_{R}-df_{F}} (p-1)}{SS_{F}/df_F(N-p)} = \frac{MS_{model}}{MS_{error}}$$

---
# Linear Modeling Approach: Treatment/Dummy

- Fit this model

.pull-left[
```{r}

lm(Quiz~Gender*Fluency, data=gen) %>%
  tidy()
```

]
.pull-right[

```{r}
lm(Quiz~Gender*Fluency, data=gen) %>%
  estimate_means()
```

]

---
# Treatment Coding/Dummy Coding

```{r, echo=FALSE}

tibble::tribble(
     ~Gender, ~Language, ~D1, ~D2, ~Interaction,
  "Female=0",     "Disfluent=0",  0L,  0L,           0L,
  "Female=0",  "Fluent=1",  0L,  1L,           0L,
    "Male=1",     "Disfluent=0",  1L,  0L,           0L,
    "Male=1",  "Fluent=1",  1L,  1L,           1L
  )

```

$$\hat{Y}= b_0 + b_1{0} + b_2 {0} + b_3{0}$$
$$\bar Y_{Female,Disfluent} = b_0$$
---

```{r, echo=FALSE}

tibble::tribble(
     ~Gender, ~Language, ~D1, ~D2, ~Interaction,
  "Female=0",     "Disfluent=0",  0L,  0L,           0L,
  "Female=0",  "Fluent=1",  0L,  1L,           0L,
    "Male=1",     "Disfluent=0",  1L,  0L,           0L,
    "Male=1",  "Fluent=1",  1L,  1L,           1L
  )

```


$$\hat{Y}= b_0 + b_1{0} + b_2 {1} + b_3{0}$$

$$\bar Y_{Female,Fluent}= b_2$$
---
```{r, echo=FALSE}

tibble::tribble(
     ~Gender, ~Language, ~D1, ~D2, ~Interaction,
  "Female=0",     "Disfluent=0",  0L,  0L,           0L,
  "Female=0",  "Fluent=1",  0L,  1L,           0L,
    "Male=1",     "Disfluent=0",  1L,  0L,           0L,
    "Male=1",  "Fluent=1",  1L,  1L,           1L
  )

```


$$\hat{Y}= b_0 + b_1{1} + b_2 {0} + b_3{0}$$
$$\bar Y_{Male,Disfluent} = b_0 + b_1 {1}$$

---
```{r, echo=FALSE}

tibble::tribble(
     ~Gender, ~Language, ~D1, ~D2, ~Interaction,
  "Female=0",     "Disfluent=0",  0L,  0L,           0L,
  "Female=0",  "Fluent=1",  0L,  1L,           0L,
    "Male=1",     "Disfluent=0",  1L,  0L,           0L,
    "Male=1",  "Fluent=1",  1L,  1L,           1L
  )

```

$$\hat{Y}= b_0 + b_1{1} + b_2 {1} + b_3{1}$$

$$\bar Y_{Male,Fluent} = b_1{1} + b_2{1} + b_3{1} $$
---
# Marginal Means: `Emmeans`

```{r}
lm(Quiz~Gender*Fluency, data=gen) %>%
  emmeans::emmeans(specs=~Gender|Fluency)
```

---
# Marginal Means:`Easystats`

```{r}
lm(Quiz~Gender*Fluency, data=gen) %>%
  estimate_means()
```

---
# Linear Modeling Approach: Sum-Coding

- Treatment coding tests simple effects in LM 

- Sum coding tests main effects/interaction effects

```{r}

contrasts(gen$Gender) <- c(0.5, -0.5)# sum code
contrasts(gen$Fluency) <- c(0.5, -0.5)# sum code

lm(Quiz~Gender*Fluency, data=gen) %>%
  tidy()

```
---
# ANOVA 

```{r}
library(afex)

aov_ez(id="id", between=c("Gender", "Fluency"), dv="Quiz", data=gen) %>%
  summary() %>% 
  tidy()
```
---
# ANOVA

```{r, echo=FALSE, fig.align='center', out.width="100%"}
  aov_ez(id="id", between=c("Gender", "Fluency"), dv="Quiz", data=gen) %>%
  afex_plot(x="Fluency", trace="Gender", between=c("Fluency", "Gender"))
```

---
# Using the F Test: Sums of Squares  

```{r, echo=FALSE, fig.align='center', out.width="50%"}

knitr::include_graphics("ss_2x2.jpg")
```
---
# Main Effect of Gender $SS_A$

> Does Gender contribute significantly over and above a intercept-only model?

```{r}
knitr::kable(tibble::tribble(
                   ~V1,                ~V2,
         "Restricted/Null model:",     "`Quiz ~ 1`",
  "Full/Alternative model:", "`Quiz ~ Gender`"
  ), col.names= c("", ""))
```

---
# F-Statistic for Gender Main Effect: $SS_A$

$$\mbox{SS}_{A} = (N \times C)  \sum_{r=1}^R  \left( \bar{Y}_{r.} - \bar{Y}_{..} \right)^2$$

.pull-left[
```{r}
r = lm(Quiz~1, data=gen) # intercept-only
f = lm(Quiz~Gender, data=gen) # gender

anova(r, f) %>% 
  knitr::kable( digits=3)#  allows us to compare models 

# aov uses type 1 ss
aov(lm(Quiz~Fluency*Gender, data=gen)) %>% 
  tidy() # clean up output
```
]

.pull_right[

```{r, echo=FALSE,  fig.align='center', out.width="100%"}
knitr::include_graphics("2wayaov.png")
```

]
---
# Main Effect of *B*

> Does Fluency contribute meaninful to the model over and above Gender?

```{r}
knitr::kable(tibble::tribble(
                   ~V1,                ~V2,
         "Restricted/Null model:",     "`Quiz ~ Gender`",
  "Full/Alternative model:", "`Quiz ~ Gender + Fluency`"
  ), col.names= c("", ""))
```


---
# F-Statistic for Fluency Main Effect: $SS_B$

$$\mbox{SS}_{B} = (N \times C)  \sum_{r=1}^R  \left( \bar{Y}_{r.} - \bar{Y}_{..} \right)^2$$

.pull-left[
```{r}

r = lm(Quiz~Gender, data=gen) # gender-only
f = lm(Quiz~Gender + Fluency , data=gen) # gender + Fluency

anova(r, f) %>%
   tidy()

# aov uses type 1 ss
aov(lm(Quiz~Gender*Fluency, data=gen)) %>% tidy(digits=3)
  
```
]

.pull_right[
```{r, echo=FALSE, fig.align='center', out.width="100%"}
knitr::include_graphics("2wayaov.png")
```
]
---
# Interaction Effect of *AB*

> Does the interaction between Fluency and Gender contribute meaninful to the model over and above the  main effects?

```{r}

knitr::kable(tibble::tribble(
                   ~V1,                ~V2,
         "Restricted/Null model:",     "`Quiz ~ Gender + Fluency`",
  "Full/Alternative model:", "`Quiz ~ Gender + Fluency + Gender:Fluency`"
  ), col.names= c("", ""))

```
---
# F-Statistic for Gender:Fluency Effect: $SS_{AB}$

.pull-left[
```{r}
r = lm(Quiz~Gender+Fluency, data=gen) # main effects only
f = lm(Quiz~Gender+Fluency + Fluency:Gender, data=gen) # main +inter

anova(r, f) %>%
  knitr::kable( digits=3)# compare both models

aov(lm(Quiz~Fluency*Gender, data=gen)) %>% tidy(digits=3)
  
```
]
.pull_right[
```{r, echo=FALSE, fig.align='center', out.width="100%"}
knitr::include_graphics("2wayaov.png")
```
]
---
# Type I, Type II, and Type III ANOVAs

- By default R `aov` calculates Type I (SS)

  - Sequential (order listed in model) 
  
    - Each term is attributed with a portion of the variation (represented by its SS) in Y that has not yet been attributed to any of the PREVIOUS terms!
    
- Can change depending on order terms are placed in the model
  
---
# Type I, Type II, and Type III ANOVAs

- Type II

  - Simultaneous SS
  
  - Based the marginality principle which states that you should not omit a lower order term from your model if there are any higher order ones that depend on it
---
- Main Effect Gender
```{r}
knitr::kable(tibble::tribble(
                   ~V1,                                               ~V2,
         "Reduced/Null model:",     "`Quiz ~ Fluency`",
  "Full.Alternative model:", "`Quiz ~ Fluency  + Gender`"
  ), col.names = c("", ""))


```
- Main effect Fluency
```{r}
knitr::kable(tibble::tribble(
                   ~V1,                                               ~V2,
         "Reduced/Null model:",     "`Quiz ~ Gender`",
  "Full/Alternative model:", "`Quiz ~ Gender + Fluency`"
  ), col.names = c("", ""))


```

- Interaction
```{r}
knitr::kable(tibble::tribble(
                   ~V1,                                               ~V2,
         "Reduced/Null model:",     "`Quiz ~ Gender + Fluency`",
  "Full/Alternative model:", "`Quiz ~ Gender + Fluency + Gender:Fluency`"
  ), col.names = c("", ""))


```

---
# Type II

- `Anova` function in `car` package can handle these cases

```{r}
library(car)

Anova(lm(Quiz~Gender*Fluency, data=gen), type="II") %>%
  tidy()
```
---
# Type I, Type II, and Type III ANOVAs

- Type III

  - Treats main effects and interactions equally
  
  - Fit full model and remove effect of interest
  
```{r}
knitr::kable(tibble::tribble(
                   ~V1,                ~V2,
         "Null model:",     "`babble ~ milk + sugar:milk`",
  "Alternative model:", "`babble ~ sugar + milk + sugar:milk`"
  ), col.names= c("", ""))
```

    - Unique contribution that is not attributable to any of the other effects in the model - main effects or interactions. So the effect of X is its unique contribution while controlling both for group and for group:X(interaction)

---
# Type III SS

```{r}
knitr::kable(tibble::tribble(
                     ~V1,                                 ~V2,                                     ~V3,

                   "`A`", "`B + C + A:B + A:C + B:C + A:B:C`", "`A + B + C + A:B + A:C + B:C + A:B:C`",
                   "`B`", "`A + C + A:B + A:C + B:C + A:B:C`", "`A + B + C + A:B + A:C + B:C + A:B:C`",
                   "`C`", "`A + B + A:B + A:C + B:C + A:B:C`", "`A + B + C + A:B + A:C + B:C + A:B:C`",
                 "`A:B`",   "`A + B + C + A:C + B:C + A:B:C`", "`A + B + C + A:B + A:C + B:C + A:B:C`",
                 "`A:C`",   "`A + B + C + A:B + B:C + A:B:C`", "`A + B + C + A:B + A:C + B:C + A:B:C`",
                 "`B:C`",   "`A + B + C + A:B + A:C + A:B:C`", "`A + B + C + A:B + A:C + B:C + A:B:C`",
               "`A:B:C`",     "`A + B + C + A:B + A:C + B:C`", "`A + B + C + A:B + A:C + B:C + A:B:C`"
  ), col.names = c(  "Term being tested is",     "Null model is `outcome ~ ...`",  "Alternative model is `outcome ~ ...`"))

```

---
# Testing Categorical x Categorial Interactions

- First look at the interaction effect

  - IF interaction effect is significant, perform mean comparisons (e.g., t-tests)

  - Pick what you care about most 

  - DON’T bother looking at involved main effects (not informative)

*For learning purposes we will examine the interaction*  

---
- Simple Effects Analysis

- An examination of the effect of one variable at one level of the other variable

```{r}
lm(Quiz~Gender*Fluency, data=gen) %>%
  emmeans::emmeans(pairwise~Gender|Fluency) %>%
  contrast(interaction = "pairwise") 
```
---
# Thoughts on Interactions

1. Avoid them if not theoretically motivated

  - Use contrasts instead 
  
2. Interactions require a lot of data

  - They are hard to power sufficiently
  
    - Power is worse in observational studies compared to experimental 

3. Use model comparison approach to determine if interactions are warranted

4. Center continuous variables and sum code categorical predictors 
---
