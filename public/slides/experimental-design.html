<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Research Methods in Cognitive Science</title>
    <meta charset="utf-8" />
    <meta name="author" content="Jason Geller, Ph.D." />
    <meta name="date" content="2021-09-29" />
    <script src="experimental-design_files/header-attrs/header-attrs.js"></script>
    <link href="experimental-design_files/countdown/countdown.css" rel="stylesheet" />
    <script src="experimental-design_files/countdown/countdown.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Research Methods in Cognitive Science
## Week 5: Experiment Basics
### Jason Geller, Ph.D.
### 2021-09-29

---





# Housekeeping

- Tuesday: Teams 1 and 2 meet me in A120

- Thursday: Sarah Colby Virtual Talk

---
Last Class

&lt;iframe src="https://app.sli.do/event/zbaasrzy" height="50%" width="100%" frameBorder="0" style="min-height: 560px;" title="Slido"&gt;&lt;/iframe&gt;


<div class="countdown" id="timer_6154d0b7" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">05</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---

# Today

- IV and DV  

- Experimental Designs: Between vs. Within

- Confounds and Selection Effects

- Critiquing Experiments

- More threats to internal validity


???

In today's lecture, we're going to talk in more detail about experimental design.

First, we're going to talk about the different types of variables that we see in experiments. We'll consider between versus within subjects designs, which represent two different types of experiments.

We'll consider two of the biggest threats to internal validity confound and selection effects.

we'll consider how to best critique the results of experiments in terms of the four validities 

and finally we will conside more threats to internal validity

---
# Experiments

&gt; Primary goal of experiments is to identify causal relationships between things in the world 

- Two pillars of experimental design: 

1. Manipulation

2. Random assignment

???
Experiments are the gold standard in cognitive science. This is becasue they allow us to make casusal claims.Experiments afford us the opportunity to say this thing causes this other thing. There are two importnat design features that allow us to do this. 
---
# Cause and Effect

- Cause
  - Independent variable (IV): Manipulated

- Effect
  - Dependent variable (DV): Measured 

???
So experiments let us set up the situation where we can observe causal relationships. When we want to see a relationship between a cause and effect, we first manipulate one variable, and that variable is called the independent variable or IV.

11
00:02:10.800 --&gt; 00:02:17.700
We then see what the consequence of that manipulation is on our dependent variable or DV.

12
00:02:18.990 --&gt; 00:02:30.840
The dependent variable is measured or observed passively, and we see whether or not it changes as we control or manipulate the independent variable.

13
00:02:31.860 --&gt; 00:02:42.180
So the independent variable or IV is our cause in our experiment, and our dependent variable or DV is our presumed effect.

14
00:02:48.000 --&gt; 00:02:53.820
Alright, let's consider an example study to help us learn a little bit more about how experiments are constructed.

---
background-image: url(expt.png)
background-position: center
background-size: cover
---
background-image: url(threat1.png)
background-position: center
background-size: cover

---
background-image: url(ran.png)
background-position: center
background-size: cover
---

# Between vs. Within Designs

- Between-participants design

&gt; Each participant experiences only one condition in the design. Chance determines which condition.

---
background-image: url(within.png)
background-position: center
background-size: cover
---
background-image: url(threat2.png)
background-position: center
background-size: cover


???

0:11:23.250 --&gt; 00:11:33.630
So here, all participants type notes in the first week of the study, and all participants then write notes in the second week of the study.

64
00:11:35.820 --&gt; 00:11:41.340
It could be that order of the treatments is explaining any results that we see.

65
00:11:42.630 --&gt; 00:11:52.830
So maybe it's the case that just observing people over time, they tend to report more symptoms when we initially observed them, than when we later observe them.

66
00:11:53.370 --&gt; 00:12:01.620
So, people might have more headaches in the first week of the study than they do in the second week of the study, just because they're kind of getting used to being observed.

67
00:12:04.740 --&gt; 00:12:08.970
A solution to order effects is called counterbalancing.
---

background-image: url(order.png)
background-position: center
background-size: cover

---
# Pros and Cons of Between and Within Designs

- Between-particpant designs:

  - Require larger sample sizes (sometimes 100s depending on effect size)
  
  - But, fewer worries about contamination across conditions

- Within-participan designs:

  - Participants serve as their own controls (increases statistical power)
  
  - Worries: Order effects, experimental demand

---

background-image: url(confound.png)
background-position: center
background-size: cover

---

background-image: url(vitc.png)
background-position: center
background-size: cover
---

background-image: url(valid.png)
background-position: center
background-size: cover

---
# Review

- Experiments have a manipulated variable (IV) and a measured variable (DV)

- Ps experience just one condition (between-Ps) or all conditions (within-Ps)

- Watch out for order effects, confounds, and selection effects

- Use the four validities to critique experiments

---
# The bad experiment

- One-group, Pre-test/Post-test design

&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;

&lt;img src="badexpt.png" width="80%" style="display: block; margin: auto;" /&gt;


---
# Maturation
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;

&gt; Participants are changing  naturally over time between  pre-test and post-test. Change  is not due to the IV.


- Rule out by using a control/comparison group.

---

# History
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;

&gt; An event intervenes between  pre-test and post-test to change participants. Changes are not due to the IV.


- Maybe something big happened in the news that was related to your study.

- Rule out by using a  control/comparison group.

---

# Regression to the mean

&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;

&gt; Participants are selected for intervention based on their extreme scores. On re-measurement, their scores become more moderate, but changes are not due to the IV

  - A group's average is extreely depressed at pretest, in part becasue some memebers volunteered for therapy when they were feeling worse

- Rule out by using a control/comparison group.

---

# Attrition
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;

&gt; Participants drop out of thestudy at different rates from  treatment group and control group

Maybe they got: 

- Illness
- Died
- left the experiment

---

# Testing

&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;

&gt; Participantsâ€™ responses change over repeated testing. Changes are not due to the IV

  - GRE verbal scores improve only becasue students take the same ersion of the test both times

- Solve by using a between-subjects, post-test only design 

---
# Instrumentation

&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;

&gt; The meaning of a measuring instrument changes over repeated use. Changes are not due to the IV.


- Coders become bored or fatigued over time


- Solve by using masked coders, randomly assigning coders to stimuli,, or training

---
background-image: url(3morethreats.png)
background-position: center
background-size: cover
---
# Review

- All told, a dozen different threats conspire to mess up causal claims

- Be attentive to control/comparison group

- Watch out for differences between  treatment and control (beyond the one  intended change)

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"slideNumberFormat": "%current%",
"highlightStyle": "github",
"highlightLines": true,
"ratio": "16:9",
"countIncrementalSlides": true,
"background-image": "url(skills.jpeg)",
"background-size": "cover"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
